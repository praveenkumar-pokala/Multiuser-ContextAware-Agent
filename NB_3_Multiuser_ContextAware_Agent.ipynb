{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *Multi*-User Conversational Tool-Calling AI Agent\n",
        "Here we will build a multi-user Conversational Agent which can refer to previous conversations and give more contextual answers by storing agent messages to a SQL database"
      ],
      "metadata": {
        "id": "8JUmAH3b5Kjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ],
      "metadata": {
        "id": "AUyVOWPl5bQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.3.14\n",
        "!pip install -q langchain-openai==0.3.0\n",
        "!pip install -q langchain-community==0.3.14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv6lN7IN5S_Z",
        "outputId": "66739f2e-8aa4-4de1-8163-bab24f01abec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.63 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.6/948.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install markitdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qba2drEj5gCz",
        "outputId": "e8fd4b33-53d8-4b65-9de1-137d766d82b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting markitdown\n",
            "  Downloading markitdown-0.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown)\n",
            "  Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting markdownify (from markitdown)\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown) (2.32.4)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (8.3.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown) (1.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown) (2025.11.12)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (25.9.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->magika~=0.6.1->markitdown)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown) (1.3.0)\n",
            "Downloading markitdown-0.1.3-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, markdownify, coloredlogs, onnxruntime, magika, markitdown\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 magika-0.6.3 markdownify-1.2.2 markitdown-0.1.3 onnxruntime-1.23.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI API Key"
      ],
      "metadata": {
        "id": "ti0nWR1D5lR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ5ihdO05iTb",
        "outputId": "172e611e-113d-4a21-b390-3830d504ca4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Open AI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ],
      "metadata": {
        "id": "fmXZGnjp5xjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCwAJTe_5uuF",
        "outputId": "1ad2b8de-e6f7-4443-e2b9-2a31e9770c3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Tavily Search API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter WeatherAPI API Key\n",
        "\n",
        "Get a free API key from [here](https://www.weatherapi.com/signup.aspx)"
      ],
      "metadata": {
        "id": "_dR8JoLu6AWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEATHER_API_KEY = getpass('Enter WeatherAPI API Key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AQptbyV54j9",
        "outputId": "3f6ee48b-2307-47ab-c2ed-756ad1a7348e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter WeatherAPI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "YNojqilv6JJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "VTbK6J_26Dvw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tools\n",
        "\n",
        "Here we create two custom tools which are wrappers on top of the [Tavily API](https://tavily.com/#api) and [WeatherAPI](https://www.weatherapi.com/)\n",
        "\n",
        "- Web Search tool with information extraction\n",
        "- Weather tool"
      ],
      "metadata": {
        "id": "fl5SWG5Q6OCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "from markitdown import MarkItDown\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "import requests\n",
        "import json\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5,\n",
        "                                  search_depth='advanced',\n",
        "                                  include_answer=False,\n",
        "                                  include_raw_content=True)\n",
        "session = requests.Session()\n",
        "session.headers.update({\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
        "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
        "})\n",
        "md = MarkItDown(requests_session=session)\n",
        "\n",
        "@tool\n",
        "def search_web_extract_info(query: str) -> list:\n",
        "    \"\"\"Search the web for a query and extracts useful information from the search links.\"\"\"\n",
        "    print('Calling web search tool')\n",
        "    results = tavily_tool.invoke(query)\n",
        "    docs = []\n",
        "\n",
        "    def extract_content(url):\n",
        "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
        "        extracted_info = md.convert(url)\n",
        "        text_title = extracted_info.title.strip()\n",
        "        text_content = extracted_info.text_content.strip()\n",
        "        return text_title + '\\n' + text_content\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for result in tqdm(results):\n",
        "            try:\n",
        "                future = executor.submit(extract_content, result['url'])\n",
        "                # Wait for up to 60 seconds for the task to complete\n",
        "                content = future.result(timeout=60)\n",
        "                docs.append(content)\n",
        "            except TimeoutError:\n",
        "                print(f\"Extraction timed out for url: {result['url']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting from url: {result['url']} - {e}\")\n",
        "\n",
        "    return docs\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_weather(query: str) -> list:\n",
        "    \"\"\"Search weatherapi to get the current weather of the queried location.\"\"\"\n",
        "    print('Calling weather tool')\n",
        "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
        "\n",
        "    response = requests.get(complete_url)\n",
        "    data = response.json()\n",
        "    if data.get(\"location\"):\n",
        "        return data\n",
        "    else:\n",
        "        return \"Weather Data Not Found\""
      ],
      "metadata": {
        "id": "wDUiqn7m6LDI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Test AI Agent\n",
        "\n",
        "Now that we have defined the tools and the LLM, we can create the agent. We will be using a tool calling agent to bind the tools to the agent with a prompt. We will also add in the capability to store historical conversations as memory"
      ],
      "metadata": {
        "id": "3xoAcuCN6VIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYS_PROMPT = \"\"\"Act as a helpful assistant.\n",
        "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
        "                At the end of the loop, you output an Answer.\n",
        "                Use Thought to describe your thoughts about the question you have been asked.\n",
        "                Use Action to run one of the actions available to you - then return PAUSE.\n",
        "                Observation will be the result of running those actions.\n",
        "                Repeat till you get to the answer for the given user query.\n",
        "\n",
        "                Use the following workflow format:\n",
        "                  Question: the input task you must solve\n",
        "                  Thought: you should always think about what to do\n",
        "                  Action: the action to take which can be any of the following:\n",
        "                            - break it into smaller steps if needed\n",
        "                            - see if you can answer the given task with your trained knowledge\n",
        "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
        "                  Action Input: the input to the action\n",
        "                  Observation: the result of the action\n",
        "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "                  Thought: I now know the final answer\n",
        "                  Final Answer: the final answer to the original input question\n",
        "\n",
        "                Tools at your disposal to perform tasks as needed:\n",
        "                  - get_weather: whenever user asks get the weather of a place.\n",
        "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
        "             \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", SYS_PROMPT),\n",
        "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
        "        (\"human\", \"{query}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_template.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apR4v_256Qjo",
        "outputId": "f40132b4-b6e9-42fb-d5a1-f4c379f3ce98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Act as a helpful assistant.\\n                You run in a loop of Thought, Action, PAUSE, Observation.\\n                At the end of the loop, you output an Answer.\\n                Use Thought to describe your thoughts about the question you have been asked.\\n                Use Action to run one of the actions available to you - then return PAUSE.\\n                Observation will be the result of running those actions.\\n                Repeat till you get to the answer for the given user query.\\n\\n                Use the following workflow format:\\n                  Question: the input task you must solve\\n                  Thought: you should always think about what to do\\n                  Action: the action to take which can be any of the following:\\n                            - break it into smaller steps if needed\\n                            - see if you can answer the given task with your trained knowledge\\n                            - call the most relevant tools at your disposal mentioned below in case you need more information\\n                  Action Input: the input to the action\\n                  Observation: the result of the action\\n                  ... (this Thought/Action/Action Input/Observation can repeat N times)\\n                  Thought: I now know the final answer\\n                  Final Answer: the final answer to the original input question\\n\\n                Tools at your disposal to perform tasks as needed:\\n                  - get_weather: whenever user asks get the weather of a place.\\n                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\\n             \"), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={}),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can initalize the agent with the LLM, the prompt, and the tools.\n",
        "\n",
        "The agent is responsible for taking in input and deciding what actions to take.\n",
        "\n",
        "REMEMBER the Agent does not execute those actions - that is done by the AgentExecutor\n",
        "\n",
        "Note that we are passing in the model `chatgpt`, not `chatgpt_with_tools`.\n",
        "\n",
        "That is because `create_tool_calling_agent` will call `.bind_tools` for us under the hood.\n",
        "\n",
        "This should ideally be used with an LLM which supports tool \\ function calling"
      ],
      "metadata": {
        "id": "uoNNgx7N6bjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chatgpt = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "tools = [search_web_extract_info, get_weather]\n",
        "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)"
      ],
      "metadata": {
        "id": "USklRWJk6Ymg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we combine the `agent` (the brains) with the `tools` inside the `AgentExecutor` (which will repeatedly call the agent and execute tools)."
      ],
      "metadata": {
        "id": "GoSPfkHE6fkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent,\n",
        "                               tools=tools,\n",
        "                               early_stopping_method='force',\n",
        "                               max_iterations=10)"
      ],
      "metadata": {
        "id": "q6xNc8S46dsJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "response = chatgpt.invoke(query)\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "IoQCPkUN6iOJ",
        "outputId": "659e492d-eb29-441a-ade3-3ad6150d0569"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"As of my last update in October 2023, I don't have access to real-time data or specific earnings call transcripts, including Nvidia's Q4 2024 earnings call. However, I can provide a general outline of what key points are typically discussed in such earnings calls:\\n\\n1. **Financial Performance**: Overview of revenue, net income, and earnings per share compared to previous quarters and year-over-year performance.\\n\\n2. **Segment Performance**: Breakdown of performance across different business segments, such as Gaming, Data Center, Professional Visualization, and Automotive.\\n\\n3. **Market Trends**: Discussion on market conditions, demand for GPUs, and trends in AI, gaming, and data center markets.\\n\\n4. **Product Updates**: Information on new product launches, advancements in technology, and updates on existing product lines.\\n\\n5. **Guidance**: Forward-looking statements regarding expected revenue, market conditions, and strategic initiatives for the upcoming quarters.\\n\\n6. **Challenges and Risks**: Any challenges faced during the quarter, such as supply chain issues, competition, or regulatory concerns.\\n\\n7. **Strategic Initiatives**: Insights into long-term strategies, partnerships, and investments in research and development.\\n\\nFor the most accurate and detailed information, I recommend checking Nvidia's official investor relations website or financial news outlets for a summary or transcript of the earnings call.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gRmMA6C6j3C",
        "outputId": "dc2128d5-1a11-42e3-b8c5-d0ea931b3bbe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:03<00:00,  1.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbSVvKw26mo6",
        "outputId": "6432a26e-13e5-4cfe-c443-f43b05770e3b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': \"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\",\n",
              " 'output': \"Thought: I need to summarize the key points from Nvidia's Q4 2024 earnings call. The earnings call typically covers financial performance, future guidance, and strategic insights from the company's leadership. I will extract the most relevant information from the sources I found.\\n\\nAction: I will compile the key points from the earnings call summary provided in the search results.\\n\\nObservation: The key points from Nvidia's Q4 2024 earnings call include:\\n\\n1. **Record Data Center Revenue**: Nvidia reported a record data center revenue of $18.4 billion for Q4, up 27% sequentially and 409% year-over-year. Approximately 40% of this revenue was attributed to AI inference.\\n\\n2. **AI Enterprise Software Growth**: The company is seeing significant progress in its AI enterprise software, with an annualized revenue run rate of $1 billion. CEO Jensen Huang emphasized that every enterprise will likely run on Nvidia AI enterprise software.\\n\\n3. **Impact of Export Controls on China**: Nvidia's revenue from China declined significantly due to U.S. export control regulations. However, the company has started shipping alternative products that do not require licenses for the Chinese market.\\n\\n4. **Future Outlook**: For Q1 FY2025, Nvidia expects total revenue of around $24 billion, with continued growth in data center and professional visualization segments, although a seasonal decline in gaming is anticipated.\\n\\n5. **Blackwell Architecture**: The upcoming Blackwell architecture is expected to significantly enhance AI throughput and is anticipated to generate substantial revenue as production ramps up.\\n\\nThought: I now have a clear summary of the key points discussed in Nvidia's Q4 2024 earnings call.\\n\\nFinal Answer: The key points from Nvidia's Q4 2024 earnings call include record data center revenue of $18.4 billion, significant growth in AI enterprise software, a decline in revenue from China due to export controls, an optimistic revenue outlook for Q1 FY2025 of around $24 billion, and the anticipated impact of the upcoming Blackwell architecture on future performance.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "gV62OBcd6o40",
        "outputId": "697f97ef-5c82-4d54-8b9c-90f42a8ec1d3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Thought: I need to summarize the key points from Nvidia's Q4 2024 earnings call. The earnings call typically covers financial performance, future guidance, and strategic insights from the company's leadership. I will extract the most relevant information from the sources I found.\n\nAction: I will compile the key points from the earnings call summary provided in the search results.\n\nObservation: The key points from Nvidia's Q4 2024 earnings call include:\n\n1. **Record Data Center Revenue**: Nvidia reported a record data center revenue of $18.4 billion for Q4, up 27% sequentially and 409% year-over-year. Approximately 40% of this revenue was attributed to AI inference.\n\n2. **AI Enterprise Software Growth**: The company is seeing significant progress in its AI enterprise software, with an annualized revenue run rate of $1 billion. CEO Jensen Huang emphasized that every enterprise will likely run on Nvidia AI enterprise software.\n\n3. **Impact of Export Controls on China**: Nvidia's revenue from China declined significantly due to U.S. export control regulations. However, the company has started shipping alternative products that do not require licenses for the Chinese market.\n\n4. **Future Outlook**: For Q1 FY2025, Nvidia expects total revenue of around $24 billion, with continued growth in data center and professional visualization segments, although a seasonal decline in gaming is anticipated.\n\n5. **Blackwell Architecture**: The upcoming Blackwell architecture is expected to significantly enhance AI throughput and is anticipated to generate substantial revenue as production ramps up.\n\nThought: I now have a clear summary of the key points discussed in Nvidia's Q4 2024 earnings call.\n\nFinal Answer: The key points from Nvidia's Q4 2024 earnings call include record data center revenue of $18.4 billion, significant growth in AI enterprise software, a decline in revenue from China due to export controls, an optimistic revenue outlook for Q1 FY2025 of around $24 billion, and the anticipated impact of the upcoming Blackwell architecture on future performance."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Summarize the key points discussed in Intel's Q4 2024 earnings call\"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "gL7_Y3Gq6qrj",
        "outputId": "b9fed8e4-c995-4d41-f9db-0195b2f3f669"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:02<00:00,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error extracting from url: https://finance.yahoo.com/quote/INTC/earnings-calls/ - 404 Client Error: Not Found for url: https://finance.yahoo.com/quote/INTC/earnings-calls/\n",
            "Error extracting from url: https://seekingalpha.com/symbol/INTC/earnings/transcripts - 403 Client Error: Forbidden for url: https://seekingalpha.com/symbol/INTC/earnings/transcripts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Thought:** I need to summarize the key points from Intel's Q4 2024 earnings call, focusing on the financial results, strategic insights, and future guidance provided by the executives.\n\n**Action:** I will extract the relevant information from the earnings call transcript.\n\n**Observation:** The key points from Intel's Q4 2024 earnings call include:\n\n1. **Financial Performance:**\n   - Q4 revenue was $14.3 billion, up 7% sequentially.\n   - Non-GAAP gross margin was 42.1%, exceeding guidance by 260 basis points.\n   - Earnings per share (EPS) for Q4 was $0.13, compared to guidance of $0.12.\n   - Full-year revenue for 2024 was $53.1 billion, down 2.1% year-over-year.\n   - Adjusted free cash flow was negative $1.5 billion for Q4.\n\n2. **Strategic Insights:**\n   - The company is focusing on improving execution and rebuilding credibility through targeted investments.\n   - Intel aims to strengthen its position in the AI PC market, expecting to ship over 100 million AI PCs by the end of 2025.\n   - The foundry business is growing, with a healthy pipeline of potential customers and a focus on competitive offerings.\n\n3. **Future Guidance:**\n   - For Q1 2025, Intel expects revenue between $11.7 billion and $12.7 billion, reflecting a sequential decline due to macroeconomic uncertainties and inventory adjustments.\n   - Gross margin for Q1 is expected to be around 36%, with a breakeven EPS on a non-GAAP basis.\n   - The company is committed to achieving breakeven operating income for its foundry business by the end of 2027.\n\n4. **Market Challenges:**\n   - Increased competition in the AI PC category and challenges in the cloud-based AI data center market were acknowledged.\n   - The executives emphasized the need for consistent execution over the next few years to regain market share.\n\n**Thought:** I now have a clear summary of the key points discussed in Intel's Q4 2024 earnings call.\n\n**Final Answer:** The key points from Intel's Q4 2024 earnings call include a revenue of $14.3 billion (up 7% sequentially), a non-GAAP gross margin of 42.1%, and an EPS of $0.13. The company is focusing on improving execution, particularly in the AI PC market, and expects Q1 2025 revenue to be between $11.7 billion and $12.7 billion. Challenges include increased competition and macroeconomic uncertainties, with a commitment to achieving breakeven in the foundry business by 2027."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"which company's future outlook looks to be better?\n",
        "        \"\"\"\n",
        "response = agent_executor.invoke({\"query\": query})\n",
        "display(Markdown(response['output']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "qrfpPODF6tar",
        "outputId": "f5008fff-1093-4cdb-f356-2d4de4e40c33"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [00:01<00:01,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error extracting from url: https://www.weforum.org/publications/the-future-of-jobs-report-2023/ - 403 Client Error: Forbidden for url: https://www.weforum.org/publications/the-future-of-jobs-report-2023/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 4/5 [01:01<00:23, 23.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction timed out for url: https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/the-top-trends-in-tech-2023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:02<00:00, 12.41s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-261151198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m query = \"\"\"which company's future outlook looks to be better?\n\u001b[1;32m      2\u001b[0m         \"\"\"\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1330\u001b[0m             [\n\u001b[1;32m   1331\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m                 for a in self._iter_next_step(\n\u001b[0m\u001b[1;32m   1333\u001b[0m                     \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m                     \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent_action\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             yield self._perform_agent_action(\n\u001b[0m\u001b[1;32m   1416\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1435\u001b[0m                 \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             observation = tool.run(\n\u001b[0m\u001b[1;32m   1438\u001b[0m                 \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_to_raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_call_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mconfig_param\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_get_runnable_config_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"content_and_artifact\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/tools/structured.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig_param\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0m_get_runnable_config_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"StructuredTool does not support sync invocation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-227808558.py\u001b[0m in \u001b[0;36msearch_web_extract_info\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext_title\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent is doing pretty well but unfortunately it doesn't remember conversations. We will use some user-session based memory to store this and dive deeper into this in the next video."
      ],
      "metadata": {
        "id": "SyTn0VA17GXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and Test Multi-User Conversational AI Agent\n",
        "\n",
        "We will now use `SQLChatMessageHistory` which we learnt in the previous module to store separate conversation histories per user or session.\n",
        "\n",
        "This will help us build a conversational Agentic Chatbot which will be accessed by many users at the same time"
      ],
      "metadata": {
        "id": "sx6e9km57KD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removes the memory database file - usually not needed\n",
        "# you can run this only when you want to remove ALL conversation histories\n",
        "# ok if you get rm: cannot remove 'memory.db': No such file or directory  because initially no memory exists\n",
        "!rm memory.db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GKmfrnO7G0l",
        "outputId": "a100f526-25a7-4135-ce9d-eba520dbb746"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'memory.db': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# used to retrieve conversation history from database\n",
        "# based on a specific user or session ID\n",
        "def get_session_history_db(session_id):\n",
        "    return SQLChatMessageHistory(session_id, \"sqlite:///memory.db\")\n",
        "\n",
        "# create a conversation chain + agent which can load memory based on specific user or session id\n",
        "agentic_chatbot = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history_db,\n",
        "    input_messages_key=\"query\",\n",
        "    history_messages_key=\"history\",\n",
        ")\n",
        "\n",
        "# function to call the agent show results per user session\n",
        "from IPython.display import display, Markdown\n",
        "def chat_with_agent(prompt: str, session_id: str):\n",
        "    response = agentic_chatbot.invoke({\"query\": prompt},\n",
        "                                      {'configurable': { 'session_id': session_id}})\n",
        "    display(Markdown(response['output']))"
      ],
      "metadata": {
        "id": "QoNIfgPY7M2I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now simulate User 1 using the agent"
      ],
      "metadata": {
        "id": "oQvGC2fV8DNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'john001'\n",
        "prompt = \"Summarize the key points discussed in Nvidia's Q4 2024 earnings call\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "zz3Xd3Vz8Fr8",
        "outputId": "50117aae-e489-4d9b-90f2-4d2a231d185d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/history.py:596: LangChainDeprecationWarning: `connection_string` was deprecated in LangChain 0.2.2 and will be removed in 1.0. Use connection instead.\n",
            "  message_history = self.get_session_history(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:04<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Thought: I need to summarize the key points from Nvidia's Q4 2024 earnings call, focusing on the most significant developments and insights shared by the company's executives.\n\nAction: I will extract the relevant information from the search results regarding Nvidia's Q4 2024 earnings call.\n\nObservation: The key points from Nvidia's Q4 2024 earnings call include:\n\n1. **Record Data Center Revenue**: Nvidia reported a record data center revenue of $18.4 billion for Q4, contributing to a total of $47.5 billion for the fiscal year, driven largely by AI-related demand. Approximately 40% of this revenue was attributed to AI inference.\n\n2. **AI Enterprise Software Growth**: The company highlighted significant progress in its AI enterprise software, achieving a revenue run rate of $1 billion. CEO Jensen Huang emphasized the potential for this segment to grow as more enterprises adopt AI solutions.\n\n3. **Impact of Export Controls on China Revenue**: Nvidia's revenue from China declined significantly due to U.S. export control regulations. However, the company noted that this market represented only a small percentage of its overall revenue.\n\n4. **Future Outlook and Product Innovations**: Nvidia is optimistic about its upcoming Blackwell architecture, which is expected to enhance AI performance significantly. The company anticipates strong demand for its products, despite some production challenges.\n\n5. **Stock Market Reaction**: Despite strong earnings, Nvidia's stock experienced a decline in after-hours trading, attributed to cautious future guidance and unmet investor expectations.\n\nThought: I now know the final answer.\n\nFinal Answer: The key points from Nvidia's Q4 2024 earnings call include record data center revenue driven by AI, growth in AI enterprise software, challenges in the Chinese market due to export controls, optimism about the upcoming Blackwell architecture, and a mixed reaction in the stock market despite strong earnings."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What about Intel?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "Kyw0G06g8K18",
        "outputId": "13e5dec2-e2aa-499a-a085-ada0610b7429"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling web search tool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:02<00:00,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error extracting from url: https://finance.yahoo.com/quote/INTC/earnings-calls/ - 404 Client Error: Not Found for url: https://finance.yahoo.com/quote/INTC/earnings-calls/\n",
            "Error extracting from url: https://seekingalpha.com/symbol/INTC/earnings/transcripts - 403 Client Error: Forbidden for url: https://seekingalpha.com/symbol/INTC/earnings/transcripts\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Thought: I need to summarize the key points from Intel's Q4 2024 earnings call, focusing on the most significant developments and insights shared by the company's executives.\n\nAction: I will extract the relevant information from the search results regarding Intel's Q4 2024 earnings call.\n\nObservation: The key points from Intel's Q4 2024 earnings call include:\n\n1. **Revenue and Earnings Performance**: Intel reported Q4 revenue of $14.3 billion, up 7% sequentially, and earnings per share (EPS) of $0.13, exceeding guidance. However, full-year revenue was down 2.1% year-over-year at $53.1 billion.\n\n2. **Gross Margin Improvement**: The non-GAAP gross margin for Q4 was 42.1%, which was 260 basis points above guidance. The company expects gross margins to be under pressure in 2025 due to product mix and higher costs, particularly with the Lunar Lake product.\n\n3. **Foundry Services Growth**: Intel Foundry Services (IFS) revenue was $4.5 billion, showing a 3% sequential increase. The company is optimistic about its foundry strategy, which is benefiting from increased demand for AI-related chips.\n\n4. **AI PC Market Focus**: Intel is positioning itself strongly in the AI PC market, expecting to ship approximately 40 million AI PCs in 2024. The company aims to leverage its existing ecosystem and partnerships to enhance its competitive edge.\n\n5. **Guidance for Q1 2025**: Intel provided a cautious outlook for Q1 2025, forecasting revenue between $11.7 billion and $12.7 billion, reflecting macroeconomic uncertainties and typical seasonal declines. The company anticipates a sequential revenue decline across all segments.\n\nThought: I now know the final answer.\n\nFinal Answer: The key points from Intel's Q4 2024 earnings call include a revenue of $14.3 billion and EPS of $0.13, with a gross margin of 42.1%. The foundry services segment showed growth, and Intel is focusing on the AI PC market, expecting to ship 40 million units in 2024. However, the company provided a cautious outlook for Q1 2025, forecasting revenue declines due to macro uncertainties."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Which company seems to be doing better?\"\n",
        "chat_with_agent(prompt, user_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "ENY2hFaM8M61",
        "outputId": "090b6b4c-4d31-4e79-e2db-de49aa4c03ad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Thought: To determine which company, Nvidia or Intel, is performing better, I need to compare their key financial metrics, growth prospects, and market positioning based on the earnings call summaries.\n\nAction: I will analyze the key points from both companies' earnings calls to assess their performance relative to each other.\n\nObservation: \n\n1. **Revenue Performance**:\n   - **Nvidia**: Reported record data center revenue of $18.4 billion for Q4, with a total of $47.5 billion for the fiscal year, driven largely by AI demand.\n   - **Intel**: Reported Q4 revenue of $14.3 billion, with a full-year revenue of $53.1 billion, which was down 2.1% year-over-year.\n\n2. **Growth Areas**:\n   - **Nvidia**: Strong growth in AI-related products, with significant contributions from AI inference and enterprise software, achieving a revenue run rate of $1 billion.\n   - **Intel**: Focus on AI PCs and foundry services, with a sequential increase in foundry revenue but a cautious outlook for the upcoming quarter.\n\n3. **Market Sentiment**:\n   - **Nvidia**: Despite strong earnings, the stock experienced a decline in after-hours trading due to cautious future guidance.\n   - **Intel**: Provided a cautious outlook for Q1 2025, forecasting revenue declines across all segments.\n\n4. **Gross Margin**:\n   - **Nvidia**: Not specifically mentioned, but the focus on high-margin AI products suggests strong profitability.\n   - **Intel**: Non-GAAP gross margin for Q4 was 42.1%, but expected to face pressure in 2025.\n\nThought: Based on the analysis, Nvidia appears to be in a stronger position due to its record revenue growth driven by AI, while Intel is facing challenges with declining revenue and a cautious outlook.\n\nFinal Answer: Nvidia seems to be doing better than Intel, with record revenue growth driven by AI demand, while Intel is experiencing revenue declines and a cautious outlook for the upcoming quarter."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now simulate User 2 using the agent"
      ],
      "metadata": {
        "id": "-jsUASsj8VBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"how is the weather in Bangalore today? Show detailed statistics\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "libjeGjK8PLt",
        "outputId": "fd4af800-5f00-4360-af91-9418126f994c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Thought: I have received the detailed weather statistics for Bangalore. Now I can summarize this information for the user.\n\nFinal Answer: The current weather in Bangalore is as follows:\n\n- **Temperature**: 24.3°C (75.7°F)\n- **Condition**: Mist\n- **Humidity**: 61%\n- **Wind**: \n  - Speed: 13.4 mph (21.6 kph)\n  - Direction: East (80°)\n- **Pressure**: 1019.0 mb (30.09 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Cloud Cover**: 50%\n- **Visibility**: 4.0 km (2.0 miles)\n- **Dew Point**: 12.8°C (55.1°F)\n- **Feels Like**: 25.5°C (77.8°F)\n- **UV Index**: 7.3\n- **Gusts**: 15.4 mph (24.8 kph)\n\nThis data was last updated at 11:30 AM local time."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"what about Dubai?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "N-lv2TSM8YIe",
        "outputId": "8d4f8a4b-2117-4a65-afb7-27941a294280"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling weather tool\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Thought: I have obtained the current weather data for Dubai. Now I can summarize this information for the user.\n\nFinal Answer: The current weather in Dubai is as follows:\n\n- **Temperature**: 25.0°C (77.0°F)\n- **Condition**: Sunny\n- **Humidity**: 51%\n- **Wind**: \n  - Speed: 2.7 mph (4.3 kph)\n  - Direction: Southeast (138°)\n- **Pressure**: 1019.0 mb (30.09 in)\n- **Precipitation**: 0.0 mm (0.0 in)\n- **Cloud Cover**: 0%\n- **Visibility**: 10.0 km (6.0 miles)\n- **Dew Point**: 10.9°C (51.5°F)\n- **Feels Like**: 25.5°C (77.8°F)\n- **UV Index**: 2.8\n- **Gusts**: 3.6 mph (5.8 kph)\n\nThis data was last updated at 10:00 AM local time."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 'bond007'\n",
        "prompt = \"which city is hotter?\"\n",
        "chat_with_agent(prompt, user_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "2yiqSgKn8aOu",
        "outputId": "ed30b1c0-c6dd-4465-d59d-63a9d641cd53"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Thought: I need to compare the temperatures of Bangalore and Dubai to determine which city is hotter.\n\nAction: I will compare the current temperatures of both cities.\n- Bangalore: 24.3°C\n- Dubai: 25.0°C\n\nObservation: Dubai has a higher temperature than Bangalore.\n\nThought: I now know the final answer.\n\nFinal Answer: Dubai is hotter than Bangalore, with a current temperature of 25.0°C compared to Bangalore's 24.3°C."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pPqL8FiG8dtv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}